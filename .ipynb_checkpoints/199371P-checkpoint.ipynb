{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original data set is read and missing values records are dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data with missing values replaced with NAN shape= (698, 11)\n",
      "Data with missing values dropped shape= (682, 11)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv(r'data/breast-cancer-wisconsin.data.txt')\n",
    "data_withnan = data.replace(to_replace='?', value=np.nan)\n",
    "\n",
    "print(\"Data with missing values replaced with NAN shape=\", data_withnan.shape)\n",
    "\n",
    "cleaned_data = data_withnan.dropna(axis='index')\n",
    "\n",
    "print(\"Data with missing values dropped shape=\", cleaned_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data set is split to test and training and saved as csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(239, 11)\n",
      "(443, 11)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "test_size = 244/(455+244)\n",
    "train_data, test_data = train_test_split(cleaned_data, test_size=test_size)\n",
    "\n",
    "print(test_data.shape)\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_csv(r'data/breast-cancer-wisconsin-nullDropped_train.csv', index = None, header=False)\n",
    "test_data.to_csv(r'data/breast-cancer-wisconsin-nullDropped_test.csv', index = None, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing C4.5 implementation library and load above missing values dropped data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from implementation import loadCSV, growDecisionTreeFrom, classify, plot\n",
    "\n",
    "trainingData = loadCSV('data/breast-cancer-wisconsin-nullDropped_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grow the decision tree from the training data and plot it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 2: x >= 3?\n",
      "yes -> Column 3: x >= 3?\n",
      "\t\tyes -> Column 6: x >= 9?\n",
      "\t\t\t\tyes -> {4: 81}\n",
      "\t\t\t\tno  -> Column 2: x >= 5?\n",
      "\t\t\t\t\t\tyes -> Column 4: x >= 2?\n",
      "\t\t\t\t\t\t\t\tyes -> {4: 34}\n",
      "\t\t\t\t\t\t\t\tno  -> Column 0: x >= 1108370?\n",
      "\t\t\t\t\t\t\t\t\t\tyes -> {4: 5}\n",
      "\t\t\t\t\t\t\t\t\t\tno  -> {2: 2}\n",
      "\t\t\t\t\t\tno  -> Column 0: x >= 1213375?\n",
      "\t\t\t\t\t\t\t\tyes -> {2: 5}\n",
      "\t\t\t\t\t\t\t\tno  -> Column 4: x >= 4?\n",
      "\t\t\t\t\t\t\t\t\t\tyes -> Column 5: x >= 6?\n",
      "\t\t\t\t\t\t\t\t\t\t\t\tyes -> Column 0: x >= 1047630?\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\tyes -> {4: 2}\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\tno  -> {2: 1}\n",
      "\t\t\t\t\t\t\t\t\t\t\t\tno  -> {4: 7}\n",
      "\t\t\t\t\t\t\t\t\t\tno  -> Column 0: x >= 1041801?\n",
      "\t\t\t\t\t\t\t\t\t\t\t\tyes -> Column 6: x >= 3?\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\tyes -> {4: 4}\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\tno  -> Column 3: x >= 4?\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tyes -> {4: 1}\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tno  -> {2: 3}\n",
      "\t\t\t\t\t\t\t\t\t\t\t\tno  -> {2: 2}\n",
      "\t\tno  -> Column 0: x >= 1133041?\n",
      "\t\t\t\tyes -> {2: 15}\n",
      "\t\t\t\tno  -> Column 1: x >= 5?\n",
      "\t\t\t\t\t\tyes -> {4: 3}\n",
      "\t\t\t\t\t\tno  -> {2: 1}\n",
      "no  -> Column 6: x >= 5?\n",
      "\t\tyes -> Column 1: x >= 4?\n",
      "\t\t\t\tyes -> Column 4: x >= 10?\n",
      "\t\t\t\t\t\tyes -> {2: 1}\n",
      "\t\t\t\t\t\tno  -> {4: 4}\n",
      "\t\t\t\tno  -> {2: 7}\n",
      "\t\tno  -> {2: 265}\n"
     ]
    }
   ],
   "source": [
    "decisionTree = growDecisionTreeFrom(trainingData)\n",
    "plot(decisionTree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collect the predictions from the decision tree for each of the test data features split above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "\n",
    "for index, row in test_data.iloc[:,:-1].iterrows():\n",
    "    a = classify(list(row), decisionTree, dataMissing=False)\n",
    "    \n",
    "    listOfItems = a.items()\n",
    "    \n",
    "    for item  in listOfItems:\n",
    "        predictions.append(item[0])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239\n",
      "[2, 4, 2, 2, 4, 4, 2, 2, 2, 4, 4, 2, 2, 2, 4, 2, 4, 2, 2, 2, 2, 4, 2, 2, 4, 2, 4, 4, 2, 2, 2, 2, 2, 2, 4, 2, 4, 4, 4, 2, 4, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 4, 4, 2, 2, 4, 2, 4, 2, 2, 2, 2, 4, 2, 2, 2, 4, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 4, 2, 4, 2, 2, 4, 2, 2, 2, 2, 4, 2, 4, 2, 4, 2, 2, 4, 2, 2, 4, 2, 2, 2, 4, 4, 2, 4, 2, 4, 2, 2, 4, 4, 2, 4, 4, 4, 2, 2, 2, 4, 4, 2, 4, 2, 2, 2, 2, 2, 2, 4, 2, 2, 4, 4, 2, 2, 4, 4, 2, 2, 4, 2, 4, 2, 2, 4, 2, 2, 4, 2, 2, 2, 2, 2, 4, 4, 2, 2, 4, 4, 2, 2, 2, 2, 4, 4, 2, 4, 2, 4, 4, 2, 2, 4, 2, 4, 2, 2, 4, 2, 4, 2, 4, 2, 2, 4, 2, 4, 4, 4, 2, 2, 2, 2, 4, 4, 2, 2, 2, 2, 4, 2, 2, 2, 2, 4, 2, 2, 2, 4, 4, 2, 2, 2, 2, 4, 2, 4, 2, 2, 4, 2, 2, 2, 2, 4]\n"
     ]
    }
   ],
   "source": [
    "print(len(predictions))\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract actual class lables from test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(239,)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_class = test_data.iloc[:,-1]\n",
    "actual_class.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification report is generated to cross check the precision, recall, f1 score and support of predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      benign       0.89      0.99      0.94       141\n",
      "   malignant       0.98      0.83      0.90        98\n",
      "\n",
      "   micro avg       0.92      0.92      0.92       239\n",
      "   macro avg       0.93      0.91      0.92       239\n",
      "weighted avg       0.93      0.92      0.92       239\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "print(classification_report(actual_class, predictions, target_names=['benign','malignant']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion matrix and accuracy of the model is calculated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix = True positives: 81 , true negatives: 139 , false positives: 2 , false negatives: 17\n",
      "Precision of the model = 0.9205020920502092\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(actual_class, predictions).ravel()\n",
    "print(\"Confusion matrix = True positives:\", tp, \", true negatives:\", tn, \", false positives:\", fp, \", false negatives:\", fn)\n",
    "\n",
    "print(\"Precision of the model =\", accuracy_score(actual_class, predictions, normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacing the missing values in original data with 1 and re-run\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(698, 11)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_withOne = data.replace(to_replace='?', value='1')\n",
    "data_withOne.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(244, 11)\n",
      "(454, 11)\n"
     ]
    }
   ],
   "source": [
    "test_size = 244/(455+244)\n",
    "train_data, test_data = train_test_split(data_withOne, test_size=test_size)\n",
    "\n",
    "print(test_data.shape)\n",
    "print(train_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_csv(r'data/breast-cancer-wisconsin-null_Imputed_train.csv', index = None, header=False)\n",
    "test_data.to_csv(r'data/breast-cancer-wisconsin-null_Imputed_test.csv', index = None, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column 3: x >= 3?\n",
      "yes -> Column 6: x >= 2?\n",
      "\t\tyes -> Column 4: x >= 6?\n",
      "\t\t\t\tyes -> {4: 64}\n",
      "\t\t\t\tno  -> Column 1: x >= 7?\n",
      "\t\t\t\t\t\tyes -> Column 4: x >= 5?\n",
      "\t\t\t\t\t\t\t\tyes -> Column 0: x >= 1214966?\n",
      "\t\t\t\t\t\t\t\t\t\tyes -> {4: 4}\n",
      "\t\t\t\t\t\t\t\t\t\tno  -> Column 0: x >= 1213375?\n",
      "\t\t\t\t\t\t\t\t\t\t\t\tyes -> {2: 1}\n",
      "\t\t\t\t\t\t\t\t\t\t\t\tno  -> {4: 1}\n",
      "\t\t\t\t\t\t\t\tno  -> {4: 49}\n",
      "\t\t\t\t\t\tno  -> Column 7: x >= 7?\n",
      "\t\t\t\t\t\t\t\tyes -> {4: 9}\n",
      "\t\t\t\t\t\t\t\tno  -> Column 8: x >= 3?\n",
      "\t\t\t\t\t\t\t\t\t\tyes -> Column 0: x >= 1065726?\n",
      "\t\t\t\t\t\t\t\t\t\t\t\tyes -> {4: 10}\n",
      "\t\t\t\t\t\t\t\t\t\t\t\tno  -> Column 0: x >= 846832?\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\tyes -> {2: 3}\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\tno  -> Column 0: x >= 616240?\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tyes -> Column 0: x >= 695091?\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tyes -> {4: 1}\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tno  -> {2: 1}\n",
      "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tno  -> {4: 1}\n",
      "\t\t\t\t\t\t\t\t\t\tno  -> {2: 4}\n",
      "\t\tno  -> Column 1: x >= 7?\n",
      "\t\t\t\tyes -> {4: 9}\n",
      "\t\t\t\tno  -> Column 4: x >= 3?\n",
      "\t\t\t\t\t\tyes -> Column 0: x >= 1201936?\n",
      "\t\t\t\t\t\t\t\tyes -> {4: 3}\n",
      "\t\t\t\t\t\t\t\tno  -> Column 1: x >= 4?\n",
      "\t\t\t\t\t\t\t\t\t\tyes -> {2: 2}\n",
      "\t\t\t\t\t\t\t\t\t\tno  -> {4: 1}\n",
      "\t\t\t\t\t\tno  -> {2: 21}\n",
      "no  -> Column 6: x >= 6?\n",
      "\t\tyes -> {4: 5}\n",
      "\t\tno  -> {2: 265}\n"
     ]
    }
   ],
   "source": [
    "trainingData = loadCSV('data/breast-cancer-wisconsin-null_Imputed_train.csv')\n",
    "decisionTree = growDecisionTreeFrom(trainingData)\n",
    "plot(decisionTree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "\n",
    "for index, row in test_data.iloc[:,:-1].iterrows():\n",
    "    a = classify(list(row), decisionTree, dataMissing=False)\n",
    "    \n",
    "    listOfItems = a.items()\n",
    "    \n",
    "    for item  in listOfItems:\n",
    "        predictions.append(item[0])\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "244\n",
      "[4, 4, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 4, 2, 2, 2, 4, 4, 4, 2, 4, 2, 2, 4, 4, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 4, 4, 2, 4, 2, 2, 2, 4, 2, 2, 2, 4, 4, 2, 2, 4, 2, 2, 2, 2, 4, 4, 2, 2, 4, 2, 2, 4, 4, 2, 4, 2, 4, 2, 4, 4, 2, 2, 2, 2, 4, 2, 2, 4, 2, 2, 4, 2, 2, 2, 2, 4, 4, 2, 2, 2, 2, 4, 4, 2, 2, 2, 2, 2, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 4, 2, 2, 2, 2, 4, 4, 2, 4, 2, 2, 4, 2, 2, 2, 2, 2, 2, 4, 2, 4, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 2, 2, 4, 2, 2, 4, 4, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 2, 4, 2, 2, 2, 4, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 4, 2, 4, 2, 2, 2, 2, 4, 4, 2, 2, 4, 4, 4, 4, 2, 2, 2]\n"
     ]
    }
   ],
   "source": [
    "print(len(predictions))\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(244,)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_class = test_data.iloc[:,-1]\n",
    "actual_class.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "      benign       0.88      0.97      0.92       160\n",
      "   malignant       0.94      0.74      0.83        84\n",
      "\n",
      "   micro avg       0.89      0.89      0.89       244\n",
      "   macro avg       0.91      0.86      0.87       244\n",
      "weighted avg       0.90      0.89      0.89       244\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(actual_class, predictions, target_names=['benign','malignant']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix = True positives: 62 , true negatives: 156 , false positives: 4 , false negatives: 22\n",
      "Precision of the model = 0.8934426229508197\n"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(actual_class, predictions).ravel()\n",
    "print(\"Confusion matrix = True positives:\", tp, \", true negatives:\", tn, \", false positives:\", fp, \", false negatives:\", fn)\n",
    "\n",
    "print(\"Precision of the model =\", accuracy_score(actual_class, predictions, normalize=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
